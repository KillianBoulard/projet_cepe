---
title: "Projet climat LBP"
output: html_notebook
authors: "Laurent BIGAS, Mathieu DA SILVA, Killian BOULARD"
---

# Etape 1 : Déclaration des librairies
```{r warning=FALSE}
library(tidymodels)
library(tidyverse)
library(geosphere)
library(purrr)
library(lubridate)
library(FactoMineR)
library(corrplot)
library(missMDA)
library(psych)
library("writexl")
library(caret)
```

```{r setup}
knitr::opts_knit$set(root.dir = "c:/Users/User/Desktop/Cours et documents/formation/formation R ensae/DATA")
knitr::opts_knit$set(root.dir = "C:/Users/VOYK743/Desktop/Fichiers Perso/Formation ENSAI/Datasets")
dataset = readRDS(file = "c:/Users/User/Desktop/Cours et documents/formation R ensae/DATA/dataset.RDS")
set.seed(42)
dataset = dataset[sample(1:nrow(dataset)), ]
```

# Etape 1 : Création de l'échantillon

```{r}
rm(list = setdiff(ls(), c("dataset")))
new_data <- c("2021")
target_train_test <- c("2011", "2012","2013","2014","2015","2016","2017","2018","2019","2020")

set.seed(42)

#2.36% de Y == 1
train_test_set = dataset %>% 
  filter(annee %in% target_train_test)

new_data = dataset %>% 
  filter(annee %in% new_data)

#Les données sont déséquilibrées, donc remise en forme des proportions
#20 185 / 855 480 = 2.36%
#En appliquant la méthode X3 /3 cela donne 60 555 / 285 160 soit 21.24%
poids_presence_feu <- 4000 * 0.5
poids_non_feu <- 4000 * 0.5

echantillon_A <- train_test_set %>% filter(Y == "1") %>% sample_n(size = poids_presence_feu, replace = FALSE)
echantillon_B <- train_test_set %>% filter(Y == "0") %>% sample_n(size = poids_non_feu, replace = FALSE)
train_test_set <- bind_rows(echantillon_A, echantillon_B)
train_test_set = train_test_set[sample(1:nrow(train_test_set)), ]
rm(echantillon_A,echantillon_B)

#Au cas ou : tester sur les données fraiches
#poids_presence_feu_new_data <- 9500 * 0.2
#poids_non_feu_new_data <- 9500 * 0.8
#echantillon_A <- new_data %>% filter(Y == "1") %>% sample_n(size = #poids_presence_feu_new_data, replace = FALSE)
#echantillon_B <- new_data %>% filter(Y == "0") %>% sample_n(size = #poids_non_feu_new_data, replace = FALSE)
#new_data <- bind_rows(echantillon_A, echantillon_B)
#new_data = new_data[sample(1:nrow(new_data)), ]
#rm(echantillon_A,echantillon_B)

#Création des datasets train / test avec proportion de 80%
i <- createDataPartition(y = train_test_set$Y, times = 1, p = 0.8, list = FALSE)
training_set <- train_test_set[i,]
test_set <- train_test_set[-i,]

training_set = training_set %>% 
  select(-c(annee, code_insee, id_station))

test_set = test_set %>% 
  select(-c(annee, code_insee, id_station))

#new_dataset = dataset %>% 
#  filter(annee %in% new_data) %>% 
#  select(-c(annee, code_insee, id_station))

training_set = training_set[sample(1:nrow(training_set)), ]
test_set = test_set[sample(1:nrow(test_set)), ]
rm(train_test_set, i, poids_presence_feu,poids_non_feu, target_train_test)
```

# Etape 2 : Modélisation

```{r}
#KNN
preProcess <-  c("center", "scale", "nzv")
#trControl <- trainControl(method = "repeatedcv",number = 5,repeats = 5)
#trControl <- trainControl(method = "timeslice",
#                          initialWindows
#                          number = 10)

model <- train(Y ~ ., method='knn', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)

test_set$pred <- predict(model, test_set[,-which(names(test_set) == "Y")])

test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Y)

precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Y)


new_data$pred <- predict(model, new_data[,-which(names(new_data) == "Y")])
new_data$factor_pred <- as.factor(new_data$pred)
new_data$factor_truth <- as.factor(new_data$Y)

precision <- posPredValue(new_data$factor_truth, new_data$factor_pred)
cm <- confusionMatrix(new_data$pred, new_data$Y)

```


```{r}
#XGB 1 : 
preProcess <-  c("center", "scale", "nzv")
xgb_trcontrol = trainControl(method = "cv", number = 10, allowParallel = TRUE, 
    verboseIter = FALSE, returnData = FALSE)

xgbGrid <- expand.grid(nrounds = c(100,200),  
                       max_depth = c(3, 5, 10, 15, 20),
                       colsample_bytree = seq(0.5, 0.9, length.out = 5),
                       ## valeurs par défaut : 
                       eta = 0.1, 
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )

xgbGrid <- expand.grid(nrounds = c(100), 
                       max_depth = c(3, 10),
                       colsample_bytree = 0.5,
                       ## valeurs par défaut : 
                       eta = c(0.1,0.05), 
                       gamma=0,
                       min_child_weight = 1,
                       subsample = 1
                      )

set.seed(42)
xgb_model = train(Y ~ .,
                  trControl = xgb_trcontrol,
                  tuneGrid = xgbGrid, 
                  #preProcess = preProcess,
                  method = "xgbTree",
                  data = training_set,
                  verbosity = 1)

test_set$pred <- predict(xgb_model, test_set[,-which(names(test_set) == "Y")])
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Y)

precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Y)


new_data$pred <- predict(xgb_model, new_data[,-which(names(new_data) == "Y")])
new_data$factor_pred <- as.factor(new_data$pred)
new_data$factor_truth <- as.factor(new_data$Y)

precision <- posPredValue(new_data$factor_truth, new_data$factor_pred)
cm <- confusionMatrix(new_data$pred, new_data$Y)

varImp(xgb_model,scale=FALSE)


#saveRDS(xgb_model, file = "c:/Users/User/Desktop/Cours et documents/formation R ensae/projet_cepe/projet_cepe/presentation_shiny/XGboost.rda")

```

```{r}
#3 sda (Shrinkage Discriminant Analysis)
metric = "Accuracy"
new_data = new_data[1:153]
set.seed(12345)
control <- trainControl(method="cv", number=10)
m_sda <- train(Y~., data=training_set, method="sda", metric=metric, 
               
               trControl=control, preProcess = c("center", "scale","nzv") )

test_set$pred <- predict(m_sda, test_set[,-which(names(test_set) == "Y")])
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Y)

precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Y)


new_data$pred <- predict(m_sda, new_data[,-which(names(new_data) == "Y")])
new_data$factor_pred <- as.factor(new_data$pred)
new_data$factor_truth <- as.factor(new_data$Y)

precision <- posPredValue(new_data$factor_truth, new_data$factor_pred)
cm <- confusionMatrix(new_data$pred, new_data$Y)

varImp(xgb_model,scale=FALSE)
```

```{r}
#2 (pda) Penalized Discriminant Analysis
metric = "Accuracy"
new_data = new_data[1:153]
control <- trainControl(method="cv", number=10)
set.seed(12345)
m_pda <- train(Y ~ ., data=training_set, method="pda", metric=metric, 
               trControl=control, preProcess = c("center", "scale","nzv") )

test_set$pred <- predict(m_pda, test_set[,-which(names(test_set) == "Y")])
test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$Y)

precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
cm <- confusionMatrix(test_set$pred, test_set$Y)


new_data$pred <- predict(m_pda, new_data[,-which(names(new_data) == "Y")])
new_data$factor_pred <- as.factor(new_data$pred)
new_data$factor_truth <- as.factor(new_data$Y)

precision <- posPredValue(new_data$factor_truth, new_data$factor_pred)
cm <- confusionMatrix(new_data$pred, new_data$Y)

varImp(xgb_model,scale=FALSE)
```
