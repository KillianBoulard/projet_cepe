---
title: "Projet climat LBP"
output: html_notebook
authors: "Laurent BIGAS, Mathieu DA SILVA, Killian BOULARD"
---

# Etape 1 : Déclaration des librairies
```{r warning=FALSE}
library(tidymodels)
library(tidyverse)
library(geosphere)
library(purrr)
library(lubridate)
library(FactoMineR)
library(corrplot)
library(missMDA)
library(psych)
library("writexl")
library(caret)
```

```{r setup}
knitr::opts_knit$set(root.dir = "c:/Users/User/Desktop/Cours et documents/formation R ensae/DATA")
knitr::opts_knit$set(root.dir = "C:/Users/VOYK743/Desktop/Fichiers Perso/Formation ENSAI/Datasets")
```

# Etape 1 : Corélation des variables

```{r}
mcor <- cor(dataset)
corrplot(mcor, type="upper", order="hclust", tl.col="black", tl.srt=45)
```

```{r}
target_test_set <- c("2021", "2022")
target_train_set <- c("2011", "2012","2013","2014","2015","2016","2017","2018","2019","2020")

set.seed(42)

training_set = dataset %>% 
  filter(annee %in% target_train_set)

test_set = dataset %>% 
  filter(annee %in% target_test_set) %>% 
  select(-c(Y))

write.csv(training_set, "C:/Users/VOYK743/Downloads/training_set.csv", row.names=TRUE)
write.csv(test_set, "C:/Users/VOYK743/Downloads/training_set.csv", row.names=TRUE)


#Travail sur échantillon pour des raisons de temps de calcul 
x <- sample(1:nrow(training_set), 10000)
training_set = training_set[x, ]

x <- sample(1:nrow(test_set), 10000)
test_set = test_set[x, ]


preProcess <- c("center","scale")
trControl <- trainControl(method = "repeatedcv",number = 2,repeats = 2)

model <- train(Y ~ ., method='knn', data = training_set, metric='Accuracy',preProcess = preProcess, trControl=trControl)

test_set$pred <- predict(model, test_set)

test_set$factor_pred <- as.factor(test_set$pred)
test_set$factor_truth <- as.factor(test_set$output)
precision <- posPredValue(test_set$factor_truth, test_set$factor_pred)
recall <- sensitivity(test_set$factor_truth, test_set$factor_pred)



set.seed(42)
train_split = initial_split(training, prop = 0.8, strata = target)
train_set = training(train_split)
eval_set = testing(train_split)
train_set

cat(dim(train_set),'/',dim(eval_set),'/',dim(test_set))
```


```{r}
## Etape 1 : Techniques de clustering / corélations des variables
########################################### tentative de PCA #########################
x <- sample(1:nrow(base_dataset_full), 100000)
test_acp = base_dataset_full[x, ]
test_acp <- test_acp %>% select(-annee,-mois,-code_insee)
test_acp = scale(test_acp)
res.pca <- PCA(test_acp, graph = TRUE)
######################################################################################

### matrice de corrélation des données 
mcor <- (cor(test_acp))
mcor
df<-as.data.frame((mcor))
corrplot(mcor,type="upper", order="hclust", tl.col="black", tl.srt=45)
corrplot(mcor, method = 'circle', order = 'AOE', diag = FALSE)

corrplot(mcor)
test<-METEO_QUANTI[1:10000,c("id_station","date_mesure","heure_mesure")]

cor(base_dataset_full, method = c("pearson", "kendall", "spearman"))
 sapply(base_dataset_full,class)
```

